{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "152db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795db960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61bdde7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    drop2 = Sequential()\n",
    "    drop2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop2.add(Dropout(0.2))\n",
    "    drop2.add(Dense(512, activation='relu'))\n",
    "    drop2.add(Dropout(0.2))\n",
    "    drop2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop2.summary()  \n",
    "\n",
    "    drop2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98c2e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    drop2_batch = Sequential()\n",
    "    drop2_batch.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop2_batch.add(Dropout(0.2))\n",
    "    drop2_batch.add(BatchNormalization())\n",
    "    drop2_batch.add(Dense(512, activation='relu'))\n",
    "    drop2_batch.add(Dropout(0.2))\n",
    "    drop2_batch.add(BatchNormalization())\n",
    "    drop2_batch.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop2_batch.summary()\n",
    "\n",
    "    drop2_batch.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecf25f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 1.1964 - accuracy: 0.6194 - val_loss: 0.7336 - val_accuracy: 0.7558\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7406 - accuracy: 0.7520 - val_loss: 0.6155 - val_accuracy: 0.7909\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.6476 - accuracy: 0.7793 - val_loss: 0.5576 - val_accuracy: 0.8116\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.8216\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5588 - accuracy: 0.8096 - val_loss: 0.5021 - val_accuracy: 0.8297\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5347 - accuracy: 0.8160 - val_loss: 0.4841 - val_accuracy: 0.8358\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5134 - accuracy: 0.8234 - val_loss: 0.4705 - val_accuracy: 0.8392\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4967 - accuracy: 0.8299 - val_loss: 0.4583 - val_accuracy: 0.8436\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4863 - accuracy: 0.8313 - val_loss: 0.4557 - val_accuracy: 0.8409\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4728 - accuracy: 0.8353 - val_loss: 0.4435 - val_accuracy: 0.8467\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4652 - accuracy: 0.8387 - val_loss: 0.4387 - val_accuracy: 0.8476\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4571 - accuracy: 0.8416 - val_loss: 0.4285 - val_accuracy: 0.8503\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4450 - accuracy: 0.8445 - val_loss: 0.4262 - val_accuracy: 0.8508\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4399 - accuracy: 0.8474 - val_loss: 0.4171 - val_accuracy: 0.8553\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4329 - accuracy: 0.8498 - val_loss: 0.4088 - val_accuracy: 0.8576\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.4258 - accuracy: 0.8499 - val_loss: 0.4091 - val_accuracy: 0.8582\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4202 - accuracy: 0.8533 - val_loss: 0.4020 - val_accuracy: 0.8595\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.4153 - accuracy: 0.8535 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4109 - accuracy: 0.8562 - val_loss: 0.3921 - val_accuracy: 0.8627\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4043 - accuracy: 0.8577 - val_loss: 0.3897 - val_accuracy: 0.8638\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3971 - accuracy: 0.8614 - val_loss: 0.3866 - val_accuracy: 0.8643\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3956 - accuracy: 0.8608 - val_loss: 0.3874 - val_accuracy: 0.8635\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3908 - accuracy: 0.8615 - val_loss: 0.3814 - val_accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3880 - accuracy: 0.8626 - val_loss: 0.3765 - val_accuracy: 0.8689\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 0.3739 - val_accuracy: 0.8687\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.3781 - accuracy: 0.8659 - val_loss: 0.3706 - val_accuracy: 0.8702\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.3759 - accuracy: 0.8676 - val_loss: 0.3696 - val_accuracy: 0.8696\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.3716 - accuracy: 0.8669 - val_loss: 0.3676 - val_accuracy: 0.8703\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3688 - accuracy: 0.8680 - val_loss: 0.3642 - val_accuracy: 0.8720\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3626 - val_accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3619 - accuracy: 0.8715 - val_loss: 0.3605 - val_accuracy: 0.8719\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3592 - accuracy: 0.8719 - val_loss: 0.3593 - val_accuracy: 0.8733\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3562 - accuracy: 0.8731 - val_loss: 0.3571 - val_accuracy: 0.8733\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3545 - accuracy: 0.8739 - val_loss: 0.3564 - val_accuracy: 0.8729\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3499 - accuracy: 0.8755 - val_loss: 0.3547 - val_accuracy: 0.8737\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3496 - accuracy: 0.8750 - val_loss: 0.3501 - val_accuracy: 0.8771\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3455 - accuracy: 0.8767 - val_loss: 0.3499 - val_accuracy: 0.8762\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3446 - accuracy: 0.8756 - val_loss: 0.3472 - val_accuracy: 0.8762\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3422 - accuracy: 0.8778 - val_loss: 0.3476 - val_accuracy: 0.8773\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3412 - accuracy: 0.8773 - val_loss: 0.3453 - val_accuracy: 0.8781\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3377 - accuracy: 0.8792 - val_loss: 0.3479 - val_accuracy: 0.8773\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3339 - accuracy: 0.8808 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.3418 - val_accuracy: 0.8786\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.3306 - accuracy: 0.8817 - val_loss: 0.3398 - val_accuracy: 0.8790\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.3274 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8787\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.3273 - accuracy: 0.8823 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3241 - accuracy: 0.8835 - val_loss: 0.3370 - val_accuracy: 0.8806\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3221 - accuracy: 0.8854 - val_loss: 0.3364 - val_accuracy: 0.8792\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.3198 - accuracy: 0.8857 - val_loss: 0.3335 - val_accuracy: 0.8813\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3179 - accuracy: 0.8857 - val_loss: 0.3365 - val_accuracy: 0.8811\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3163 - accuracy: 0.8877 - val_loss: 0.3304 - val_accuracy: 0.8833\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3124 - accuracy: 0.8881 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.3126 - accuracy: 0.8878 - val_loss: 0.3332 - val_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.3124 - accuracy: 0.8871 - val_loss: 0.3275 - val_accuracy: 0.8832\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3077 - accuracy: 0.8889 - val_loss: 0.3284 - val_accuracy: 0.8827\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3070 - accuracy: 0.8902 - val_loss: 0.3268 - val_accuracy: 0.8839\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.3066 - accuracy: 0.8913 - val_loss: 0.3243 - val_accuracy: 0.8844\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3236 - val_accuracy: 0.8848\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.3019 - accuracy: 0.8924 - val_loss: 0.3236 - val_accuracy: 0.8855\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3002 - accuracy: 0.8929 - val_loss: 0.3224 - val_accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "drop2_history = drop2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4445493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 9s 21ms/step - loss: 0.7280 - accuracy: 0.7477 - val_loss: 0.4989 - val_accuracy: 0.8299\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5100 - accuracy: 0.8196 - val_loss: 0.4094 - val_accuracy: 0.8518\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4589 - accuracy: 0.8365 - val_loss: 0.3900 - val_accuracy: 0.8601\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4278 - accuracy: 0.8465 - val_loss: 0.3758 - val_accuracy: 0.8668\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4033 - accuracy: 0.8545 - val_loss: 0.3638 - val_accuracy: 0.8700\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3848 - accuracy: 0.8620 - val_loss: 0.3501 - val_accuracy: 0.8728\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3702 - accuracy: 0.8674 - val_loss: 0.3511 - val_accuracy: 0.8730\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3573 - accuracy: 0.8712 - val_loss: 0.3470 - val_accuracy: 0.8749\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.3490 - accuracy: 0.8746 - val_loss: 0.3396 - val_accuracy: 0.8760\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.3392 - accuracy: 0.8785 - val_loss: 0.3293 - val_accuracy: 0.8813\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3286 - accuracy: 0.8814 - val_loss: 0.3317 - val_accuracy: 0.8807\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.3225 - accuracy: 0.8812 - val_loss: 0.3230 - val_accuracy: 0.8824\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.3142 - accuracy: 0.8850 - val_loss: 0.3258 - val_accuracy: 0.8840\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.3074 - accuracy: 0.8877 - val_loss: 0.3188 - val_accuracy: 0.8868\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2988 - accuracy: 0.8911 - val_loss: 0.3148 - val_accuracy: 0.8847\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2973 - accuracy: 0.8912 - val_loss: 0.3167 - val_accuracy: 0.8836\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2915 - accuracy: 0.8943 - val_loss: 0.3185 - val_accuracy: 0.8845\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2824 - accuracy: 0.8968 - val_loss: 0.3154 - val_accuracy: 0.8860\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2770 - accuracy: 0.8982 - val_loss: 0.3132 - val_accuracy: 0.8866\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2755 - accuracy: 0.8983 - val_loss: 0.3097 - val_accuracy: 0.8874\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.2676 - accuracy: 0.9016 - val_loss: 0.3144 - val_accuracy: 0.8840\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2623 - accuracy: 0.9031 - val_loss: 0.3176 - val_accuracy: 0.8845\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.2591 - accuracy: 0.9058 - val_loss: 0.3127 - val_accuracy: 0.8865\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.2534 - accuracy: 0.9071 - val_loss: 0.3090 - val_accuracy: 0.8862\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2503 - accuracy: 0.9064 - val_loss: 0.3116 - val_accuracy: 0.8880\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.2480 - accuracy: 0.9091 - val_loss: 0.3101 - val_accuracy: 0.8893\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2416 - accuracy: 0.9113 - val_loss: 0.3051 - val_accuracy: 0.8923\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.2404 - accuracy: 0.9110 - val_loss: 0.3055 - val_accuracy: 0.8902\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.2344 - accuracy: 0.9145 - val_loss: 0.3034 - val_accuracy: 0.8921\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.2323 - accuracy: 0.9142 - val_loss: 0.3041 - val_accuracy: 0.8906\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2284 - accuracy: 0.9153 - val_loss: 0.3020 - val_accuracy: 0.8914\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2249 - accuracy: 0.9169 - val_loss: 0.3077 - val_accuracy: 0.8906\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2227 - accuracy: 0.9173 - val_loss: 0.3029 - val_accuracy: 0.8913\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2200 - accuracy: 0.9189 - val_loss: 0.3032 - val_accuracy: 0.8919\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2155 - accuracy: 0.9192 - val_loss: 0.3035 - val_accuracy: 0.8913\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.2120 - accuracy: 0.9204 - val_loss: 0.3023 - val_accuracy: 0.8937\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.2109 - accuracy: 0.9222 - val_loss: 0.3013 - val_accuracy: 0.8925\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.2063 - accuracy: 0.9235 - val_loss: 0.3045 - val_accuracy: 0.8929\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.2012 - accuracy: 0.9240 - val_loss: 0.3057 - val_accuracy: 0.8927\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 11s 31ms/step - loss: 0.2018 - accuracy: 0.9255 - val_loss: 0.3023 - val_accuracy: 0.8943\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 13s 34ms/step - loss: 0.1972 - accuracy: 0.9277 - val_loss: 0.3089 - val_accuracy: 0.8919\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.1976 - accuracy: 0.9271 - val_loss: 0.3089 - val_accuracy: 0.8935\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1935 - accuracy: 0.9280 - val_loss: 0.3150 - val_accuracy: 0.8914\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1917 - accuracy: 0.9297 - val_loss: 0.3094 - val_accuracy: 0.8929\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1876 - accuracy: 0.9303 - val_loss: 0.3161 - val_accuracy: 0.8912\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.1845 - accuracy: 0.9312 - val_loss: 0.3055 - val_accuracy: 0.8957\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.1819 - accuracy: 0.9323 - val_loss: 0.3107 - val_accuracy: 0.8942\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.1784 - accuracy: 0.9331 - val_loss: 0.3168 - val_accuracy: 0.8931\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.1780 - accuracy: 0.9342 - val_loss: 0.3066 - val_accuracy: 0.8924\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1740 - accuracy: 0.9365 - val_loss: 0.3172 - val_accuracy: 0.8911\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.1747 - accuracy: 0.9354 - val_loss: 0.3118 - val_accuracy: 0.8954\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 10s 26ms/step - loss: 0.1726 - accuracy: 0.9356 - val_loss: 0.3109 - val_accuracy: 0.8929\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.1704 - accuracy: 0.9367 - val_loss: 0.3167 - val_accuracy: 0.8938\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.1648 - accuracy: 0.9384 - val_loss: 0.3117 - val_accuracy: 0.8960\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1652 - accuracy: 0.9376 - val_loss: 0.3238 - val_accuracy: 0.8917\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.1615 - accuracy: 0.9392 - val_loss: 0.3144 - val_accuracy: 0.8941\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.1630 - accuracy: 0.9391 - val_loss: 0.3178 - val_accuracy: 0.8925\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.1586 - accuracy: 0.9413 - val_loss: 0.3142 - val_accuracy: 0.8953\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1558 - accuracy: 0.9413 - val_loss: 0.3245 - val_accuracy: 0.8926\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1540 - accuracy: 0.9432 - val_loss: 0.3196 - val_accuracy: 0.8951\n"
     ]
    }
   ],
   "source": [
    "drop2_batch_history = drop2_batch.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a74956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    drop5 = Sequential()\n",
    "    drop5.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop5.add(Dropout(0.5))\n",
    "    drop5.add(Dense(512, activation='relu'))\n",
    "    drop5.add(Dropout(0.5))\n",
    "    drop5.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop5.summary()\n",
    "\n",
    "    drop5.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "221cac6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    drop5_batch = Sequential()\n",
    "    drop5_batch.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop5_batch.add(Dropout(0.5))\n",
    "    drop5_batch.add(BatchNormalization())\n",
    "    drop5_batch.add(Dense(512, activation='relu'))\n",
    "    drop5_batch.add(Dropout(0.5))\n",
    "    drop5_batch.add(BatchNormalization())\n",
    "    drop5_batch.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop5_batch.summary() \n",
    "\n",
    "    drop5_batch.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7225a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.4087 - accuracy: 0.5072 - val_loss: 0.8206 - val_accuracy: 0.7200\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.9034 - accuracy: 0.6816 - val_loss: 0.6809 - val_accuracy: 0.7562\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7810 - accuracy: 0.7254 - val_loss: 0.6170 - val_accuracy: 0.7846\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7135 - accuracy: 0.7482 - val_loss: 0.5798 - val_accuracy: 0.7988\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6665 - accuracy: 0.7650 - val_loss: 0.5459 - val_accuracy: 0.8109\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6306 - accuracy: 0.7828 - val_loss: 0.5268 - val_accuracy: 0.8139\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.6044 - accuracy: 0.7906 - val_loss: 0.5062 - val_accuracy: 0.8229\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5871 - accuracy: 0.7972 - val_loss: 0.4937 - val_accuracy: 0.8268\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.5639 - accuracy: 0.8036 - val_loss: 0.4821 - val_accuracy: 0.8286\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.5499 - accuracy: 0.8093 - val_loss: 0.4715 - val_accuracy: 0.8322\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.5343 - accuracy: 0.8135 - val_loss: 0.4615 - val_accuracy: 0.8364\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5190 - accuracy: 0.8185 - val_loss: 0.4529 - val_accuracy: 0.8387\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5127 - accuracy: 0.8197 - val_loss: 0.4475 - val_accuracy: 0.8388\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5014 - accuracy: 0.8242 - val_loss: 0.4394 - val_accuracy: 0.8432\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4930 - accuracy: 0.8280 - val_loss: 0.4320 - val_accuracy: 0.8446\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4861 - accuracy: 0.8297 - val_loss: 0.4298 - val_accuracy: 0.8457\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4792 - accuracy: 0.8319 - val_loss: 0.4236 - val_accuracy: 0.8454\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4722 - accuracy: 0.8330 - val_loss: 0.4200 - val_accuracy: 0.8505\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4676 - accuracy: 0.8354 - val_loss: 0.4140 - val_accuracy: 0.8519\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4625 - accuracy: 0.8378 - val_loss: 0.4085 - val_accuracy: 0.8531\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4553 - accuracy: 0.8392 - val_loss: 0.4078 - val_accuracy: 0.8537\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4517 - accuracy: 0.8405 - val_loss: 0.4043 - val_accuracy: 0.8541\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4443 - accuracy: 0.8449 - val_loss: 0.4007 - val_accuracy: 0.8562\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4421 - accuracy: 0.8443 - val_loss: 0.3969 - val_accuracy: 0.8563\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4372 - accuracy: 0.8446 - val_loss: 0.3940 - val_accuracy: 0.8597\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.4312 - accuracy: 0.8470 - val_loss: 0.3904 - val_accuracy: 0.8595\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.4283 - accuracy: 0.8479 - val_loss: 0.3883 - val_accuracy: 0.8618\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.4256 - accuracy: 0.8493 - val_loss: 0.3851 - val_accuracy: 0.8610\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.4233 - accuracy: 0.8509 - val_loss: 0.3822 - val_accuracy: 0.8627\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.4197 - accuracy: 0.8509 - val_loss: 0.3822 - val_accuracy: 0.8632\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.4153 - accuracy: 0.8537 - val_loss: 0.3785 - val_accuracy: 0.8644\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4128 - accuracy: 0.8535 - val_loss: 0.3776 - val_accuracy: 0.8639\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4058 - accuracy: 0.8557 - val_loss: 0.3751 - val_accuracy: 0.8648\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4082 - accuracy: 0.8557 - val_loss: 0.3746 - val_accuracy: 0.8647\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4018 - accuracy: 0.8559 - val_loss: 0.3728 - val_accuracy: 0.8664\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3995 - accuracy: 0.8579 - val_loss: 0.3682 - val_accuracy: 0.8683\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3992 - accuracy: 0.8604 - val_loss: 0.3673 - val_accuracy: 0.8677\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3957 - accuracy: 0.8592 - val_loss: 0.3657 - val_accuracy: 0.8683\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3948 - accuracy: 0.8603 - val_loss: 0.3647 - val_accuracy: 0.8688\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3907 - accuracy: 0.8612 - val_loss: 0.3618 - val_accuracy: 0.8716\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3885 - accuracy: 0.8599 - val_loss: 0.3619 - val_accuracy: 0.8695\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3852 - accuracy: 0.8627 - val_loss: 0.3601 - val_accuracy: 0.8698\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3837 - accuracy: 0.8624 - val_loss: 0.3572 - val_accuracy: 0.8719\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3818 - accuracy: 0.8642 - val_loss: 0.3560 - val_accuracy: 0.8716\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3802 - accuracy: 0.8636 - val_loss: 0.3564 - val_accuracy: 0.8715\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3757 - accuracy: 0.8671 - val_loss: 0.3533 - val_accuracy: 0.8738\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3769 - accuracy: 0.8668 - val_loss: 0.3534 - val_accuracy: 0.8733\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3748 - accuracy: 0.8670 - val_loss: 0.3513 - val_accuracy: 0.8727\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3728 - accuracy: 0.8694 - val_loss: 0.3504 - val_accuracy: 0.8750\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3690 - accuracy: 0.8687 - val_loss: 0.3518 - val_accuracy: 0.8733\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3677 - accuracy: 0.8687 - val_loss: 0.3472 - val_accuracy: 0.8761\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3643 - accuracy: 0.8699 - val_loss: 0.3467 - val_accuracy: 0.8765\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3638 - accuracy: 0.8692 - val_loss: 0.3473 - val_accuracy: 0.8748\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3617 - accuracy: 0.8696 - val_loss: 0.3452 - val_accuracy: 0.8764\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3590 - accuracy: 0.8736 - val_loss: 0.3436 - val_accuracy: 0.8759\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3564 - accuracy: 0.8730 - val_loss: 0.3429 - val_accuracy: 0.8772\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3589 - accuracy: 0.8709 - val_loss: 0.3413 - val_accuracy: 0.8782\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3548 - accuracy: 0.8741 - val_loss: 0.3411 - val_accuracy: 0.8782\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3551 - accuracy: 0.8731 - val_loss: 0.3402 - val_accuracy: 0.8788\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3545 - accuracy: 0.8744 - val_loss: 0.3388 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "drop5_history = drop5.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68543e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 8s 19ms/step - loss: 1.0753 - accuracy: 0.6304 - val_loss: 0.5882 - val_accuracy: 0.7993\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6938 - accuracy: 0.7538 - val_loss: 0.4827 - val_accuracy: 0.8241\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6114 - accuracy: 0.7837 - val_loss: 0.4460 - val_accuracy: 0.8375\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5705 - accuracy: 0.7980 - val_loss: 0.4310 - val_accuracy: 0.8432\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5372 - accuracy: 0.8092 - val_loss: 0.4175 - val_accuracy: 0.8466\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5137 - accuracy: 0.8175 - val_loss: 0.4078 - val_accuracy: 0.8515\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4926 - accuracy: 0.8232 - val_loss: 0.3991 - val_accuracy: 0.8561\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4815 - accuracy: 0.8269 - val_loss: 0.3938 - val_accuracy: 0.8592\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4616 - accuracy: 0.8347 - val_loss: 0.3848 - val_accuracy: 0.8608\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4586 - accuracy: 0.8379 - val_loss: 0.3791 - val_accuracy: 0.8647\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4470 - accuracy: 0.8398 - val_loss: 0.3744 - val_accuracy: 0.8641\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4373 - accuracy: 0.8463 - val_loss: 0.3676 - val_accuracy: 0.8652\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4304 - accuracy: 0.8462 - val_loss: 0.3654 - val_accuracy: 0.8669\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4219 - accuracy: 0.8486 - val_loss: 0.3646 - val_accuracy: 0.8693\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4190 - accuracy: 0.8500 - val_loss: 0.3613 - val_accuracy: 0.8689\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4126 - accuracy: 0.8524 - val_loss: 0.3603 - val_accuracy: 0.8689\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4056 - accuracy: 0.8530 - val_loss: 0.3524 - val_accuracy: 0.8748\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4008 - accuracy: 0.8541 - val_loss: 0.3515 - val_accuracy: 0.8740\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3968 - accuracy: 0.8568 - val_loss: 0.3491 - val_accuracy: 0.8733\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3899 - accuracy: 0.8607 - val_loss: 0.3479 - val_accuracy: 0.8732\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3872 - accuracy: 0.8607 - val_loss: 0.3456 - val_accuracy: 0.8773\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3822 - accuracy: 0.8629 - val_loss: 0.3489 - val_accuracy: 0.8745\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3831 - accuracy: 0.8625 - val_loss: 0.3449 - val_accuracy: 0.8778\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3719 - accuracy: 0.8643 - val_loss: 0.3388 - val_accuracy: 0.8780\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3727 - accuracy: 0.8641 - val_loss: 0.3425 - val_accuracy: 0.8764\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3672 - accuracy: 0.8674 - val_loss: 0.3336 - val_accuracy: 0.8809\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3658 - accuracy: 0.8685 - val_loss: 0.3346 - val_accuracy: 0.8805\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.3618 - accuracy: 0.8686 - val_loss: 0.3330 - val_accuracy: 0.8800\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3580 - accuracy: 0.8709 - val_loss: 0.3323 - val_accuracy: 0.8794\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3522 - accuracy: 0.8719 - val_loss: 0.3280 - val_accuracy: 0.8817\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3502 - accuracy: 0.8716 - val_loss: 0.3277 - val_accuracy: 0.8816\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3497 - accuracy: 0.8722 - val_loss: 0.3265 - val_accuracy: 0.8822\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3462 - accuracy: 0.8750 - val_loss: 0.3261 - val_accuracy: 0.8823\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3409 - accuracy: 0.8758 - val_loss: 0.3223 - val_accuracy: 0.8842\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3418 - accuracy: 0.8761 - val_loss: 0.3240 - val_accuracy: 0.8831\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3357 - accuracy: 0.8767 - val_loss: 0.3214 - val_accuracy: 0.8836\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3374 - accuracy: 0.8772 - val_loss: 0.3224 - val_accuracy: 0.8815\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3343 - accuracy: 0.8774 - val_loss: 0.3176 - val_accuracy: 0.8845\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3316 - accuracy: 0.8800 - val_loss: 0.3221 - val_accuracy: 0.8830\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.3322 - accuracy: 0.8783 - val_loss: 0.3203 - val_accuracy: 0.8832\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3274 - accuracy: 0.8813 - val_loss: 0.3184 - val_accuracy: 0.8852\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3289 - accuracy: 0.8809 - val_loss: 0.3191 - val_accuracy: 0.8842\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3249 - accuracy: 0.8817 - val_loss: 0.3146 - val_accuracy: 0.8853\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3233 - accuracy: 0.8811 - val_loss: 0.3171 - val_accuracy: 0.8836\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.3181 - accuracy: 0.8830 - val_loss: 0.3188 - val_accuracy: 0.8831\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3181 - accuracy: 0.8843 - val_loss: 0.3165 - val_accuracy: 0.8865\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3140 - accuracy: 0.8842 - val_loss: 0.3151 - val_accuracy: 0.8878\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3112 - accuracy: 0.8873 - val_loss: 0.3125 - val_accuracy: 0.8865\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3104 - accuracy: 0.8853 - val_loss: 0.3116 - val_accuracy: 0.8878\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3115 - accuracy: 0.8876 - val_loss: 0.3141 - val_accuracy: 0.8856\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3054 - accuracy: 0.8895 - val_loss: 0.3127 - val_accuracy: 0.8863\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3074 - accuracy: 0.8873 - val_loss: 0.3093 - val_accuracy: 0.8867\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3022 - accuracy: 0.8891 - val_loss: 0.3203 - val_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3007 - accuracy: 0.8890 - val_loss: 0.3075 - val_accuracy: 0.8867\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3012 - accuracy: 0.8887 - val_loss: 0.3117 - val_accuracy: 0.8872\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2964 - accuracy: 0.8914 - val_loss: 0.3076 - val_accuracy: 0.8889\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2960 - accuracy: 0.8921 - val_loss: 0.3055 - val_accuracy: 0.8873\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2941 - accuracy: 0.8911 - val_loss: 0.3086 - val_accuracy: 0.8875\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2906 - accuracy: 0.8930 - val_loss: 0.3043 - val_accuracy: 0.8881\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2947 - accuracy: 0.8915 - val_loss: 0.3046 - val_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "drop5_batch_history = drop5_batch.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f27aca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    drop8 = Sequential()\n",
    "    drop8.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop8.add(Dropout(0.8))\n",
    "    drop8.add(Dense(512, activation='relu'))\n",
    "    drop8.add(Dropout(0.8))\n",
    "    drop8.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop8.summary()\n",
    "\n",
    "    drop8.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6592988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    drop8_batch = Sequential()\n",
    "    drop8_batch.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    drop8_batch.add(Dropout(0.8))\n",
    "    drop8_batch.add(BatchNormalization())\n",
    "    drop8_batch.add(Dense(512, activation='relu'))\n",
    "    drop8_batch.add(Dropout(0.8))\n",
    "    drop8_batch.add(BatchNormalization())\n",
    "    drop8_batch.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    drop8_batch.summary()\n",
    "\n",
    "    drop8_batch.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccf90a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9802 - accuracy: 0.2981 - val_loss: 1.2360 - val_accuracy: 0.6743\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.3864 - accuracy: 0.4942 - val_loss: 0.8993 - val_accuracy: 0.7020\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1488 - accuracy: 0.5750 - val_loss: 0.7811 - val_accuracy: 0.7172\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 1.0306 - accuracy: 0.6193 - val_loss: 0.7262 - val_accuracy: 0.7379\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.9507 - accuracy: 0.6475 - val_loss: 0.6806 - val_accuracy: 0.7613\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.8940 - accuracy: 0.6706 - val_loss: 0.6534 - val_accuracy: 0.7631\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8535 - accuracy: 0.6860 - val_loss: 0.6239 - val_accuracy: 0.7792\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.8175 - accuracy: 0.7025 - val_loss: 0.6049 - val_accuracy: 0.7837\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.7878 - accuracy: 0.7145 - val_loss: 0.5883 - val_accuracy: 0.7931\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7615 - accuracy: 0.7236 - val_loss: 0.5747 - val_accuracy: 0.7963\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7388 - accuracy: 0.7336 - val_loss: 0.5565 - val_accuracy: 0.8027\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7228 - accuracy: 0.7389 - val_loss: 0.5440 - val_accuracy: 0.8063\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.7073 - accuracy: 0.7445 - val_loss: 0.5340 - val_accuracy: 0.8106\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6908 - accuracy: 0.7527 - val_loss: 0.5242 - val_accuracy: 0.8163\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6812 - accuracy: 0.7574 - val_loss: 0.5167 - val_accuracy: 0.8208\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6667 - accuracy: 0.7634 - val_loss: 0.5108 - val_accuracy: 0.8219\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6598 - accuracy: 0.7666 - val_loss: 0.5007 - val_accuracy: 0.8248\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6457 - accuracy: 0.7713 - val_loss: 0.4953 - val_accuracy: 0.8273\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6368 - accuracy: 0.7744 - val_loss: 0.4860 - val_accuracy: 0.8294\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6286 - accuracy: 0.7780 - val_loss: 0.4827 - val_accuracy: 0.8327\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6244 - accuracy: 0.7803 - val_loss: 0.4766 - val_accuracy: 0.8303\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.6150 - accuracy: 0.7837 - val_loss: 0.4754 - val_accuracy: 0.8342\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6072 - accuracy: 0.7868 - val_loss: 0.4665 - val_accuracy: 0.8334\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6030 - accuracy: 0.7888 - val_loss: 0.4648 - val_accuracy: 0.8360\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5967 - accuracy: 0.7910 - val_loss: 0.4604 - val_accuracy: 0.8377\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5860 - accuracy: 0.7939 - val_loss: 0.4563 - val_accuracy: 0.8366\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5916 - accuracy: 0.7959 - val_loss: 0.4537 - val_accuracy: 0.8395\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5772 - accuracy: 0.7985 - val_loss: 0.4532 - val_accuracy: 0.8407\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5747 - accuracy: 0.8000 - val_loss: 0.4470 - val_accuracy: 0.8423\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5706 - accuracy: 0.8002 - val_loss: 0.4469 - val_accuracy: 0.8420\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5678 - accuracy: 0.8015 - val_loss: 0.4440 - val_accuracy: 0.8435\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5607 - accuracy: 0.8044 - val_loss: 0.4389 - val_accuracy: 0.8429\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5565 - accuracy: 0.8046 - val_loss: 0.4382 - val_accuracy: 0.8447\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5533 - accuracy: 0.8093 - val_loss: 0.4346 - val_accuracy: 0.8467\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5472 - accuracy: 0.8086 - val_loss: 0.4313 - val_accuracy: 0.8469\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5484 - accuracy: 0.8097 - val_loss: 0.4294 - val_accuracy: 0.8472\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5435 - accuracy: 0.8108 - val_loss: 0.4279 - val_accuracy: 0.8470\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5395 - accuracy: 0.8115 - val_loss: 0.4263 - val_accuracy: 0.8486\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5391 - accuracy: 0.8140 - val_loss: 0.4257 - val_accuracy: 0.8497\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5343 - accuracy: 0.8154 - val_loss: 0.4247 - val_accuracy: 0.8501\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5306 - accuracy: 0.8154 - val_loss: 0.4192 - val_accuracy: 0.8498\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5258 - accuracy: 0.8165 - val_loss: 0.4206 - val_accuracy: 0.8495\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5220 - accuracy: 0.8187 - val_loss: 0.4176 - val_accuracy: 0.8525\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5243 - accuracy: 0.8186 - val_loss: 0.4195 - val_accuracy: 0.8518\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5171 - accuracy: 0.8199 - val_loss: 0.4126 - val_accuracy: 0.8528\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5141 - accuracy: 0.8196 - val_loss: 0.4136 - val_accuracy: 0.8542\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5155 - accuracy: 0.8212 - val_loss: 0.4099 - val_accuracy: 0.8542\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5093 - accuracy: 0.8226 - val_loss: 0.4106 - val_accuracy: 0.8538\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5106 - accuracy: 0.8236 - val_loss: 0.4090 - val_accuracy: 0.8553\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5024 - accuracy: 0.8254 - val_loss: 0.4085 - val_accuracy: 0.8566\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5044 - accuracy: 0.8238 - val_loss: 0.4067 - val_accuracy: 0.8558\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5031 - accuracy: 0.8246 - val_loss: 0.4062 - val_accuracy: 0.8562\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5005 - accuracy: 0.8263 - val_loss: 0.4031 - val_accuracy: 0.8562\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4957 - accuracy: 0.8269 - val_loss: 0.4012 - val_accuracy: 0.8586\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4954 - accuracy: 0.8269 - val_loss: 0.4007 - val_accuracy: 0.8579\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4953 - accuracy: 0.8282 - val_loss: 0.3999 - val_accuracy: 0.8591\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.4899 - accuracy: 0.8305 - val_loss: 0.3977 - val_accuracy: 0.8586\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4917 - accuracy: 0.8289 - val_loss: 0.3983 - val_accuracy: 0.8599\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4880 - accuracy: 0.8304 - val_loss: 0.3966 - val_accuracy: 0.8613\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.4901 - accuracy: 0.8303 - val_loss: 0.3973 - val_accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "drop8_history = drop8.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44672b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 10s 22ms/step - loss: 2.0283 - accuracy: 0.3183 - val_loss: 1.0200 - val_accuracy: 0.6870\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 1.3142 - accuracy: 0.5218 - val_loss: 0.7974 - val_accuracy: 0.7144\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 1.0927 - accuracy: 0.5969 - val_loss: 0.7252 - val_accuracy: 0.7338\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.9787 - accuracy: 0.6388 - val_loss: 0.6853 - val_accuracy: 0.7455\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.9103 - accuracy: 0.6648 - val_loss: 0.6509 - val_accuracy: 0.7600\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.8676 - accuracy: 0.6798 - val_loss: 0.6252 - val_accuracy: 0.7718\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.8329 - accuracy: 0.6956 - val_loss: 0.6099 - val_accuracy: 0.7800\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.7932 - accuracy: 0.7114 - val_loss: 0.5927 - val_accuracy: 0.7882\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.7721 - accuracy: 0.7209 - val_loss: 0.5780 - val_accuracy: 0.7928\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.7475 - accuracy: 0.7291 - val_loss: 0.5677 - val_accuracy: 0.7978\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.7314 - accuracy: 0.7362 - val_loss: 0.5557 - val_accuracy: 0.8007\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.7164 - accuracy: 0.7430 - val_loss: 0.5439 - val_accuracy: 0.8072\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.7073 - accuracy: 0.7485 - val_loss: 0.5307 - val_accuracy: 0.8110\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.6918 - accuracy: 0.7527 - val_loss: 0.5338 - val_accuracy: 0.8116\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.6781 - accuracy: 0.7571 - val_loss: 0.5252 - val_accuracy: 0.8118\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.6714 - accuracy: 0.7618 - val_loss: 0.5134 - val_accuracy: 0.8197\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.6634 - accuracy: 0.7633 - val_loss: 0.5058 - val_accuracy: 0.8209\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.6504 - accuracy: 0.7688 - val_loss: 0.4977 - val_accuracy: 0.8236\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.6422 - accuracy: 0.7736 - val_loss: 0.4883 - val_accuracy: 0.8263\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.6305 - accuracy: 0.7771 - val_loss: 0.4907 - val_accuracy: 0.8252\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.6286 - accuracy: 0.7784 - val_loss: 0.4844 - val_accuracy: 0.8281\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.6208 - accuracy: 0.7827 - val_loss: 0.4882 - val_accuracy: 0.8262\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.6171 - accuracy: 0.7831 - val_loss: 0.4743 - val_accuracy: 0.8317\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.6072 - accuracy: 0.7853 - val_loss: 0.4701 - val_accuracy: 0.8338\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.6042 - accuracy: 0.7854 - val_loss: 0.4687 - val_accuracy: 0.8352\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5997 - accuracy: 0.7894 - val_loss: 0.4627 - val_accuracy: 0.8361\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5915 - accuracy: 0.7931 - val_loss: 0.4602 - val_accuracy: 0.8363\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5915 - accuracy: 0.7931 - val_loss: 0.4611 - val_accuracy: 0.8375\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5828 - accuracy: 0.7944 - val_loss: 0.4535 - val_accuracy: 0.8395\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5827 - accuracy: 0.7946 - val_loss: 0.4529 - val_accuracy: 0.8407\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5740 - accuracy: 0.7986 - val_loss: 0.4477 - val_accuracy: 0.8432\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5728 - accuracy: 0.7970 - val_loss: 0.4475 - val_accuracy: 0.8427\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5694 - accuracy: 0.7996 - val_loss: 0.4448 - val_accuracy: 0.8450\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.5645 - accuracy: 0.8017 - val_loss: 0.4441 - val_accuracy: 0.8447\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5566 - accuracy: 0.8061 - val_loss: 0.4425 - val_accuracy: 0.8457\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5567 - accuracy: 0.8040 - val_loss: 0.4348 - val_accuracy: 0.8462\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5538 - accuracy: 0.8061 - val_loss: 0.4367 - val_accuracy: 0.8468\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5570 - accuracy: 0.8045 - val_loss: 0.4365 - val_accuracy: 0.8462\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5477 - accuracy: 0.8079 - val_loss: 0.4324 - val_accuracy: 0.8474\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5447 - accuracy: 0.8104 - val_loss: 0.4361 - val_accuracy: 0.8463\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.5430 - accuracy: 0.8117 - val_loss: 0.4280 - val_accuracy: 0.8494\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5421 - accuracy: 0.8117 - val_loss: 0.4255 - val_accuracy: 0.8522\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5398 - accuracy: 0.8121 - val_loss: 0.4260 - val_accuracy: 0.8507\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5345 - accuracy: 0.8139 - val_loss: 0.4267 - val_accuracy: 0.8495\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5308 - accuracy: 0.8151 - val_loss: 0.4244 - val_accuracy: 0.8491\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.5297 - accuracy: 0.8160 - val_loss: 0.4240 - val_accuracy: 0.8506\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5302 - accuracy: 0.8172 - val_loss: 0.4174 - val_accuracy: 0.8527\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5298 - accuracy: 0.8140 - val_loss: 0.4182 - val_accuracy: 0.8513\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.5221 - accuracy: 0.8186 - val_loss: 0.4164 - val_accuracy: 0.8545\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5196 - accuracy: 0.8175 - val_loss: 0.4170 - val_accuracy: 0.8518\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.5230 - accuracy: 0.8162 - val_loss: 0.4146 - val_accuracy: 0.8538\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5154 - accuracy: 0.8180 - val_loss: 0.4111 - val_accuracy: 0.8535\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5152 - accuracy: 0.8204 - val_loss: 0.4134 - val_accuracy: 0.8533\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5105 - accuracy: 0.8220 - val_loss: 0.4119 - val_accuracy: 0.8543\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5089 - accuracy: 0.8217 - val_loss: 0.4079 - val_accuracy: 0.8568\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5088 - accuracy: 0.8227 - val_loss: 0.4116 - val_accuracy: 0.8572\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5058 - accuracy: 0.8235 - val_loss: 0.4070 - val_accuracy: 0.8568\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5015 - accuracy: 0.8245 - val_loss: 0.4086 - val_accuracy: 0.8568\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.5077 - accuracy: 0.8229 - val_loss: 0.4042 - val_accuracy: 0.8585\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5026 - accuracy: 0.8242 - val_loss: 0.4038 - val_accuracy: 0.8599\n"
     ]
    }
   ],
   "source": [
    "drop8_batch_history = drop8_batch.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16d4e530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8761\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3510 - accuracy: 0.8893\n",
      "\n",
      "dropout 0.2 \n",
      "\n",
      "\n",
      "dropout rate(0.2) Accuracy: 87.61%\n",
      "dropout rate(0.2) & batch normalization Accuracy: 88.93%\n",
      "\n",
      "Adding batch nomalization gets more Accuracy\n"
     ]
    }
   ],
   "source": [
    "metrics1 = drop2.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "#print(metrics[1])\n",
    "metrics2 = drop2_batch.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'\\ndropout 0.2 \\n')\n",
    "print(f'\\ndropout rate(0.2) Accuracy: {metrics1[1]*100:.2f}%')\n",
    "print(f'dropout rate(0.2) & batch normalization Accuracy: {metrics2[1]*100:.2f}%\\n')\n",
    "\n",
    "if(metrics1[1]<metrics2[1]):\n",
    "    print(f'Adding batch nomalization gets more Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d5bb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3625 - accuracy: 0.8702\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3271 - accuracy: 0.8841\n",
      "\n",
      "dropout 0.5 \n",
      "\n",
      "\n",
      "dropout rate(0.5) Accuracy: 87.02%\n",
      "dropout rate(0.5) & batch normalization Accuracy: 88.41%\n",
      "\n",
      "Adding batch nomalization gets more Accuracy\n"
     ]
    }
   ],
   "source": [
    "metrics1 = drop5.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "#print(metrics[1])\n",
    "metrics2 = drop5_batch.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'\\ndropout 0.5 \\n')\n",
    "print(f'\\ndropout rate(0.5) Accuracy: {metrics1[1]*100:.2f}%')\n",
    "print(f'dropout rate(0.5) & batch normalization Accuracy: {metrics2[1]*100:.2f}%\\n')\n",
    "\n",
    "if(metrics1[1]<metrics2[1]):\n",
    "    print(f'Adding batch nomalization gets more Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1044c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.4184 - accuracy: 0.8511\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4246 - accuracy: 0.8499\n",
      "\n",
      "dropout 0.8 \n",
      "\n",
      "\n",
      "dropout rate(0.8) Accuracy: 85.11%\n",
      "dropout rate(0.8) & batch normalization Accuracy: 84.99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics1 = drop8.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "#print(metrics[1])\n",
    "metrics2 = drop8_batch.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'\\ndropout 0.8 \\n')\n",
    "print(f'\\ndropout rate(0.8) Accuracy: {metrics1[1]*100:.2f}%')\n",
    "print(f'dropout rate(0.8) & batch normalization Accuracy: {metrics2[1]*100:.2f}%\\n')\n",
    "\n",
    "if(metrics1[1]<metrics2[1]):\n",
    "    print(f'Adding batch nomalization gets more Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "532f7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 결과 관찰 \n",
      "\n",
      "Drop-out 은 0~1 사이의 확률로 랜덤하게 뉴런을 제거하는 방법이다. 이는 일부 뉴런들로도 결과 값이 잘 나올 수 있을 때 일반적으로 모든 instance 각각의 결과값에 평균을 구해 전체의 결과값을 구할 수 있는데 이는 편향되지 않은 결과를 얻는데 일반적으로 좋다. 즉 특정 feature에 대해 overfitting을 방지하고 나머지 feature역시 확인할 수 있다. generalization 측면에서 drop-out 을 쓴다. 이때 우리가 알아본 dropout을 0.8까지 올리면 너무 많은 뉴런을 제거하기 때문에 오히려 정확도가 떨어질 수 있음을 알 수 있게 되었다.\n",
      "\n",
      "batch normalization은 학습 과정 중 각 배치 단위 별로 평균, 분산을 조정하는 정규화하여 입력값이 한쪽으로 쏠리는 것을 막아준다. 일반적으로 zero mean guassian 형태로 평균 0, 표준 편차는 1로 만든다. 이렇게 할 시 feature가 동일한 scale이 되어 같은 gradient descent에 따른 weight에 대한 반응이 같아진다.(scale이 다를 시 각 gradient가 달라지고 이로 인해 gradient가 큰 weight는 gradient exploding, 작다면 vanishing이 발생할 수 있다. 이는 정확도를 더이상 증가 시키지 못하고 local minima에 빠지거나 수렴할 것이다.) 또한 ReLu activation function 앞에 적용하여 음수 부분이 0이 되지 않도록 한다. 그리고 추론 단계에서는 학습 단계에서 평균을 계산한 평균, 분산의 고정값을 이용한다. 그래서 이번 프로젝트에서 일반적으로 Bach normalization을 적용한 것이 정확도가 더 높게 나옴을 알 수 있다.\n"
     ]
    }
   ],
   "source": [
    "print(f'실험 결과 관찰 \\n')\n",
    "print(f'Drop-out 은 0~1 사이의 확률로 랜덤하게 뉴런을 제거하는 방법이다. 이는 일부 뉴런들로도 결과 값이 잘 나올 수 있을 때 일반적으로 모든 instance 각각의 결과값에 평균을 구해 전체의 결과값을 구할 수 있는데 이는 편향되지 않은 결과를 얻는데 일반적으로 좋다. 즉 특정 feature에 대해 overfitting을 방지하고 나머지 feature역시 확인할 수 있다. generalization 측면에서 drop-out 을 쓴다. 이때 우리가 알아본 dropout을 0.8까지 올리면 너무 많은 뉴런을 제거하기 때문에 오히려 정확도가 떨어질 수 있음을 알 수 있게 되었다.\\n')\n",
    "print(f'batch normalization은 학습 과정 중 각 배치 단위 별로 평균, 분산을 조정하는 정규화하여 입력값이 한쪽으로 쏠리는 것을 막아준다. 일반적으로 zero mean guassian 형태로 평균 0, 표준 편차는 1로 만든다. 이렇게 할 시 feature가 동일한 scale이 되어 같은 gradient descent에 따른 weight에 대한 반응이 같아진다.(scale이 다를 시 각 gradient가 달라지고 이로 인해 gradient가 큰 weight는 gradient exploding, 작다면 vanishing이 발생할 수 있다. 이는 정확도를 더이상 증가 시키지 못하고 local minima에 빠지거나 수렴할 것이다.) 또한 ReLu activation function 앞에 적용하여 음수 부분이 0이 되지 않도록 한다. 그리고 추론 단계에서는 학습 단계에서 평균을 계산한 평균, 분산의 고정값을 이용한다. 그래서 이번 프로젝트에서 일반적으로 Bach normalization을 적용한 것이 정확도가 더 높게 나옴을 알 수 있다.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33621c4eaf1710b15d4b40b2d499ee574555d35df91c30e450d23a36004d7dfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
